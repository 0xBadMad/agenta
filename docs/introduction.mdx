---
title: Introduction
description: 'Welcome Agenta: The open source end-to-end LLMOps platform.'
---

Agenta is an open-source end-to-end platform for productionizing (complex) LLM apps. Agenta enables you to:
1. Quickly experiment with prompts, parameters and complex strategies (in-context learning with embeddings, agents...) 
2. Systematically evaluate your LLM apps
3. Deploy your application in one-click

And all of this without imposing any restrictions on your choice of framework, library, or model.

## Why use agenta?
- You need to collaborate with domain experts and want to get their feedback about your LLM apps and even their help experimenting with prompts and parameters (without having to touch your code).
- Your write your LLM apps using code and don't want to be restricted by library, model or framework. 
- You need to save, version and compare different variants of your LLM apps.
- You need a systematic way to evaluate your LLM apps **programmatically**  and with help of domain experts.
- You prefer to focus on the LLM app and not worry about the deployment and infrastructure.
- You want your data to be private and not be proxied through third-party services.

## What is not agenta?
- A single prompt playground tool. Although you can use agenta for that, it is not the main focus of the platform.
- A no-code LLM app builder. Although we offer app templates you can user from the UI, our focus is on enabling you to build complex apps in code

## Features
- **Parameter Playground:** Define the parameters of your app in your code and experiment with them (together with ) via a user-friendly web platform.

## How Agenta works:
1. Develop your LLM-powered application as you would normally do. Feel free to use any framework, library, or model (langchain, llma_index, GPT-3, or open-source models).
2. With two lines of code, specify the parameters for your experiment.
3. Deploy your app using the Agenta CLI.
4. You or your team can iterate, version parameters, test different versions, and run systematic evaluations via a user-friendly web platform.


## Key Benefits
- **Parameter Playground:** With just a few lines of code, define the parameters you wish to experiment with. Through our user-friendly web platform, you or your team can then experiment and tweak these parameters.

- **Version Evaluation:** Define test sets, evaluate, and compare different app versions.

- **API Deployment Made Easy:** Agenta allows you to deploy your LLM applications as APIs without any additional effort. (Currently only available locally)

## Why choose Agenta for building LLM-apps?

While there are numerous LLMops platforms, we believe Agenta offers unique benefits:

- Developer-Friendly: We cater to complex LLM-apps and pipelines that require more than just a few no-code abstractions. We give you the freedom to develop your apps the way you want.
- Privacy-First: We respect your privacy and do not proxy your data through third-party services. You have the choice to host your data and models.
- Solution-Agnostic: You have the freedom to use any library and models, be it Langchain, llma_index, or a custom-written alternative.
- Collaborative: We recognize that building LLM-powered apps requires the collaboration of developers and domain experts. Our tool enables this collaboration, allowing domain experts to edit and modify parameters (e.g., prompts, hyperparameters, etc.), and label results for evaluation.
- Open-Source: We encourage you to contribute to the platform and customize it to suit your needs.


<CardGroup cols={2}>
  <Card
    title="Installation"
    icon="screwdriver-wrench"
    href="installation"
  >
    Install Agenta on your local machine to get started.
  </Card>
  <Card
    title="Getting Started"
    icon="stars"
    href="getting-started"
  >
    5 minutes to get started with Agenta.
  </Card>
</CardGroup>
